{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import scipy.stats as stats\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "columns=['user','activity','time','x','y','z']\n",
    "\n",
    "\n",
    "def fetch_train_data(accelorgyro,phoneorwatch):\n",
    "    df=pd.DataFrame()\n",
    "    for i in range(20):\n",
    "        if i<10:\n",
    "            dftemp=pd.read_csv(f'/content/drive/My Drive/Colab Notebooks/a/raw/train/{phoneorwatch}/{accelorgyro}/data_160{i}_{accelorgyro}_{phoneorwatch}.txt')\n",
    "        else:\n",
    "            dftemp=pd.read_csv(f'/content/drive/My Drive/Colab Notebooks/a/raw/train/{phoneorwatch}/{accelorgyro}/data_16{i}_{accelorgyro}_{phoneorwatch}.txt')\n",
    "\n",
    "        if len(df)>0:\n",
    "            df = pd.DataFrame( np.concatenate( (df.values, dftemp.values), axis=0 ) )\n",
    "            df.columns=columns\n",
    "        else:\n",
    "            df=dftemp \n",
    "    return df\n",
    "\n",
    "\n",
    "df_train_accel_phone=fetch_train_data('accel','phone')\n",
    "df_train_accel_watch=fetch_train_data('accel','watch')\n",
    "df_train_gyro_phone=fetch_train_data('gyro','phone')\n",
    "df_train_gyro_watch=fetch_train_data('gyro','watch')\n",
    "\n",
    "#merging training dataframes into single dataframe dftrain\n",
    "\n",
    "dftrain = pd.DataFrame( np.concatenate( (df_train_accel_phone.values, df_train_accel_watch.values,df_train_gyro_phone,df_train_gyro_watch), axis=0 ) )\n",
    "dftrain.columns=columns\n",
    "dftrain.shape\n",
    "\n",
    "\n",
    "def fetch_test_data(accelorgyro,phoneorwatch):\n",
    "    df=pd.DataFrame()\n",
    "    for i in range(20,34):\n",
    "        dftemp=pd.read_csv(f'/content/drive/My Drive/Colab Notebooks/a/raw/test/{phoneorwatch}/{accelorgyro}/data_16{i}_{accelorgyro}_{phoneorwatch}.txt')\n",
    "\n",
    "        if len(df)>0:\n",
    "            df = pd.DataFrame( np.concatenate( (df.values, dftemp.values), axis=0 ) )\n",
    "            df.columns=columns\n",
    "        else:\n",
    "            df=dftemp \n",
    "    return df\n",
    "\n",
    "df_test_accel_phone=fetch_test_data('accel','phone')\n",
    "df_test_accel_watch=fetch_test_data('accel','watch')\n",
    "df_test_gyro_phone=fetch_test_data('gyro','phone')\n",
    "df_test_gyro_watch=fetch_test_data('gyro','watch')\n",
    "\n",
    "#merging testing dataframes into single dataframe dftest\n",
    "\n",
    "dftest = pd.DataFrame( np.concatenate( (df_test_accel_phone.values, df_test_accel_watch.values,df_test_gyro_phone,df_test_gyro_watch), axis=0 ) )\n",
    "dftest.columns=columns\n",
    "dftest.shape\n",
    "\n",
    "#removing semicolon from 'z' column and changing datatypes of 'x','y','z' to float as they have changed to object\n",
    "\n",
    "dftrain['time']=dftrain['time'].astype(int)\n",
    "dftest['time']=dftest['time'].astype(int)\n",
    "dftrain['z'] = dftrain['z'].str.replace(';', '')\n",
    "dftrain['z']=dftrain['z'].astype(float)\n",
    "dftrain['x']=dftrain['x'].astype(float)\n",
    "dftrain['y']=dftrain['y'].astype(float)\n",
    "dftrain['time']=dftrain['time'].astype(int)\n",
    "dftest['z'] = dftest['z'].str.replace(';', '')\n",
    "dftest['z']=dftest['z'].astype(float)\n",
    "dftest['y']=dftest['y'].astype(float)\n",
    "dftest['x']=dftest['x'].astype(float)\n",
    "\n",
    "#making a new dataframe without user and time, also getting activity count so that we can balance the dataset\n",
    "\n",
    "df1=dftrain.drop(['user','time'],axis=1).copy()\n",
    "df1['activity'].value_counts()\n",
    "\n",
    "\n",
    "#Making new dataframes with respect to each activity to make a balanced training dataframe balanced\n",
    "\n",
    "\n",
    "A=df1[df1['activity']=='A'].head(289076).copy()\n",
    "B=df1[df1['activity']=='B'].head(289076).copy()\n",
    "C=df1[df1['activity']=='C'].head(289076).copy()\n",
    "D=df1[df1['activity']=='D'].head(289076).copy()\n",
    "E=df1[df1['activity']=='E'].head(289076).copy()\n",
    "F=df1[df1['activity']=='F'].head(289076).copy()\n",
    "G=df1[df1['activity']=='G'].head(289076).copy()\n",
    "H=df1[df1['activity']=='H'].head(289076).copy()\n",
    "I=df1[df1['activity']=='I'].head(289076).copy()\n",
    "J=df1[df1['activity']=='J'].head(289076).copy()\n",
    "K=df1[df1['activity']=='K'].head(289076).copy()\n",
    "L=df1[df1['activity']=='L'].head(289076).copy()\n",
    "M=df1[df1['activity']=='M'].head(289076).copy()\n",
    "N=df1[df1['activity']=='N'].head(289076).copy()\n",
    "O=df1[df1['activity']=='O'].head(289076).copy()\n",
    "P=df1[df1['activity']=='P'].head(289076).copy()\n",
    "Q=df1[df1['activity']=='Q'].head(289076).copy()\n",
    "R=df1[df1['activity']=='R'].head(289076).copy()\n",
    "S=df1[df1['activity']=='S'].head(289076).copy()\n",
    "balanced=pd.DataFrame()\n",
    "balanced=balanced.append([A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S])\n",
    "balanced['activity'].value_counts()\n",
    "\n",
    "#making a new dataframe without user and time, also getting activity count so that we can balance the dataset\n",
    "\n",
    "dft1=dftest.drop(['user','time'],axis=1).copy()\n",
    "dft1\n",
    "dft1['activity'].value_counts()\n",
    "\n",
    "#Making new dataframes with respect to each activity to make a balanced testing dataframe balanced\n",
    "\n",
    "A=dft1[dft1['activity']=='A'].head(223312).copy()\n",
    "B=dft1[dft1['activity']=='B'].head(223312).copy()\n",
    "C=dft1[dft1['activity']=='C'].head(223312).copy()\n",
    "D=dft1[dft1['activity']=='D'].head(223312).copy()\n",
    "E=dft1[dft1['activity']=='E'].head(223312).copy()\n",
    "F=dft1[dft1['activity']=='F'].head(223312).copy()\n",
    "G=dft1[dft1['activity']=='G'].head(223312).copy()\n",
    "H=dft1[dft1['activity']=='H'].head(223312).copy()\n",
    "I=dft1[dft1['activity']=='I'].head(223312).copy()\n",
    "J=dft1[dft1['activity']=='J'].head(223312).copy()\n",
    "K=dft1[dft1['activity']=='K'].head(223312).copy()\n",
    "L=dft1[dft1['activity']=='L'].head(223312).copy()\n",
    "M=dft1[dft1['activity']=='M'].head(223312).copy()\n",
    "N=dft1[dft1['activity']=='N'].head(223312).copy()\n",
    "O=dft1[dft1['activity']=='O'].head(223312).copy()\n",
    "P=dft1[dft1['activity']=='P'].head(223312).copy()\n",
    "Q=dft1[dft1['activity']=='Q'].head(223312).copy()\n",
    "R=dft1[dft1['activity']=='R'].head(223312).copy()\n",
    "S=dft1[dft1['activity']=='S'].head(223312).copy()\n",
    "balancedt=pd.DataFrame()\n",
    "balancedt=balancedt.append([A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S])\n",
    "balancedt['activity'].value_counts()\n",
    "\n",
    "#putting labels on activities for both balanced training dataframe and balanced testing dataframe\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "\n",
    "balanced['Label']=label.fit_transform(balanced['activity'])\n",
    "balanced\n",
    "\n",
    "balancedt['Label']=label.fit_transform(balancedt['activity'])\n",
    "balancedt\n",
    "\n",
    "#Normalizing the data to get it in range of (-1,1)\n",
    "\n",
    "X=balanced[['x','y','z']]\n",
    "Y=balanced['Label']\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "scaled_x=pd.DataFrame(data=X,columns=['x','y','z'])\n",
    "scaled_x['Label']=Y.values\n",
    "scaled_x\n",
    "\n",
    "\n",
    "#Doing same for test dataframe\n",
    "\n",
    "Xt=balancedt[['x','y','z']]\n",
    "Yt=balancedt['Label']\n",
    "Xt=scaler.fit_transform(Xt)\n",
    "scaled_xt=pd.DataFrame(data=Xt,columns=['x','y','z'])\n",
    "scaled_xt['Label']=Yt.values\n",
    "scaled_xt\n",
    "\n",
    "rate=20\n",
    "frame_size=rate*4\n",
    "hop_size=rate*2\n",
    "\n",
    "#getting frames\n",
    "\n",
    "def get_frames(df,frame_size,hop_size):\n",
    "    n_features=3\n",
    "    frames=[]\n",
    "    labels=[]\n",
    "\n",
    "    for i in range(0,len(df)-frame_size,hop_size):\n",
    "        x=df['x'].values[i:i+frame_size]\n",
    "        y=df['y'].values[i:i+frame_size]\n",
    "        z=df['z'].values[i:i+frame_size]\n",
    "\n",
    "        label=stats.mode(df['Label'][i:i+frame_size])[0][0]\n",
    "        frames.append([x,y,z])\n",
    "        labels.append(label)\n",
    "    frames=np.asarray(frames).reshape(-1,frame_size,n_features)\n",
    "    labels=np.asarray(labels)\n",
    "    return frames,labels\n",
    "\n",
    "X,y=get_frames(scaled_x,frame_size,hop_size)\n",
    "Xt,yt=get_frames(scaled_xt,frame_size,hop_size)\n",
    "\n",
    "#making data 3 diamensional for neural netwrk\n",
    "\n",
    "x_train=X\n",
    "y_train=y\n",
    "print(x_train.shape)\n",
    "x_test=Xt\n",
    "y_test=yt\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train=x_train.reshape(130083,80,3,1)\n",
    "x_train[0].shape\n",
    "x_test=x_test.reshape(100489,80,3,1)\n",
    "x_test[0].shape\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(16,(2,2),activation='relu',input_shape=x_train[0].shape))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32,(2,2),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(18,activation='softmax'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.002),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                      y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      validation_data=(x_test,y_test),\n",
    "                      verbose=1)\n",
    "\n",
    "\n",
    "train_acc = model.evaluate(x_train, y_train, verbose=1)\n",
    "test_acc = model.evaluate(x_test, y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
